{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Documentation reading:\n",
        " A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness). See the documentation for `torch.Tensor` and `torch.cuda`"
      ],
      "metadata": {
        "id": "d0xUsiTZi9n5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Create a random tensor with shape (7, 7)."
      ],
      "metadata": {
        "id": "y_Kysws6lBN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "tensor = torch.rand(7,7)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cnXRvYrlKXu",
        "outputId": "c6fab6f1-88d3-4838-f6e4-5445a83d3f86"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2713, 0.2960, 0.2921, 0.6442, 0.6785, 0.0507, 0.8109],\n",
            "        [0.3739, 0.6942, 0.6393, 0.0864, 0.4062, 0.3121, 0.1234],\n",
            "        [0.9550, 0.9903, 0.7604, 0.5898, 0.2378, 0.0812, 0.7817],\n",
            "        [0.2787, 0.6305, 0.3221, 0.0278, 0.0645, 0.0603, 0.6055],\n",
            "        [0.3477, 0.0320, 0.5707, 0.1172, 0.8474, 0.5277, 0.3167],\n",
            "        [0.8421, 0.5373, 0.1233, 0.4077, 0.0779, 0.3861, 0.7119],\n",
            "        [0.1985, 0.8388, 0.2895, 0.3818, 0.9060, 0.9926, 0.8085]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7)\n",
        "(hint: you may have to transpose the second tensor)."
      ],
      "metadata": {
        "id": "viBk2O50llkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.rand(1,7)\n",
        "tensor2 = torch.rand(1,7)\n",
        "\n",
        "print(tensor1.shape)\n",
        "print(tensor2.T.shape)\n",
        "print(torch.mm(tensor1, tensor2.T))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OGiO_s2lz-P",
        "outputId": "205db424-f225-40f3-b416-3e38406c512a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 7])\n",
            "torch.Size([7, 1])\n",
            "tensor([[2.4182]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Set the random seed to 0 and do exercises 2 & 3 over again."
      ],
      "metadata": {
        "id": "Ief6ZURkmPpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 0\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "# 2nd:\n",
        "tensor_seed = torch.rand(7,7)\n",
        "print(tensor_seed)\n",
        "\n",
        "# 3rd:\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "tensor_A = torch.rand(1,7)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "tensor_B = torch.rand(1,7)\n",
        "\n",
        "print(f\"tensor_A = {tensor_A}\\n tensor_B transpose = {tensor_B.T}\")\n",
        "print(torch.matmul(tensor_A, tensor_B.T))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA0iiu6LmUOG",
        "outputId": "b14e26fa-55ca-4fd1-8f3f-dc75d918c5d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901],\n",
            "        [0.8964, 0.4556, 0.6323, 0.3489, 0.4017, 0.0223, 0.1689],\n",
            "        [0.2939, 0.5185, 0.6977, 0.8000, 0.1610, 0.2823, 0.6816],\n",
            "        [0.9152, 0.3971, 0.8742, 0.4194, 0.5529, 0.9527, 0.0362],\n",
            "        [0.1852, 0.3734, 0.3051, 0.9320, 0.1759, 0.2698, 0.1507],\n",
            "        [0.0317, 0.2081, 0.9298, 0.7231, 0.7423, 0.5263, 0.2437],\n",
            "        [0.5846, 0.0332, 0.1387, 0.2422, 0.8155, 0.7932, 0.2783]])\n",
            "tensor_A = tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901]])\n",
            " tensor_B transpose = tensor([[0.4963],\n",
            "        [0.7682],\n",
            "        [0.0885],\n",
            "        [0.1320],\n",
            "        [0.3074],\n",
            "        [0.6341],\n",
            "        [0.4901]])\n",
            "tensor([[1.5985]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Speaking of random seeds, we saw how to set it with torch.manual_seed() but is there a GPU equivalent? (hint: you'll need to look into the documentation for torch.cuda for this one). If there is, set the GPU random seed to 1234."
      ],
      "metadata": {
        "id": "ZnYRGpkbmaAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "torch.cuda.manual_seed(1234)\n",
        "\n",
        "tensor_cuda_random = torch.rand(4,4)\n",
        "\n",
        "print(tensor_cuda_random)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u08uSgptnmqx",
        "outputId": "4441c663-c722-4afe-8bd7-85001a5403ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Apr 30 00:42:01 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "True\n",
            "tensor([[0.8964, 0.4556, 0.6323, 0.3489],\n",
            "        [0.4017, 0.0223, 0.1689, 0.2939],\n",
            "        [0.5185, 0.6977, 0.8000, 0.1610],\n",
            "        [0.2823, 0.6816, 0.9152, 0.3971]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Create two random tensors of shape (2, 3) and send them both to the GPU (you'll need access to a GPU for this). Set torch.manual_seed(1234) when creating the tensors (this doesn't have to be the GPU random seed)."
      ],
      "metadata": {
        "id": "9m3gkBIxpZrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1234)\n",
        "cpu_tensor1 = torch.rand(2,3)\n",
        "cpu_tensor2 = torch.rand(2,3)\n",
        "\n",
        "print(f\"cpu_tensor1 device = {cpu_tensor1.device} \\t cpu_tensor2 device = {cpu_tensor2.device}\")\n",
        "\n",
        "device = \"cuda\" if(torch.cuda.is_available()) else \"cpu\"\n",
        "gpu_tensor1 = cpu_tensor1.to(device = device)\n",
        "# gpu_tensor2 = cpu_tensor2.cuda(device = device)\n",
        "gpu_tensor2 = torch.rand([2,3], device = device)\n",
        "\n",
        "print(f\"gpu_tensor1 device = {gpu_tensor1.device} \\t gpu_tensor2 device = {gpu_tensor2.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9Ubtu4Tpd-L",
        "outputId": "b28b4e90-d28e-4d70-e38a-0143e24ab566"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu_tensor1 device = cpu \t cpu_tensor2 device = cpu\n",
            "gpu_tensor1 device = cuda:0 \t gpu_tensor2 device = cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors)."
      ],
      "metadata": {
        "id": "Shf1OJzlrPb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_multiplication = torch.mm(gpu_tensor1, gpu_tensor2.T)\n",
        "print(matrix_multiplication)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvwEBYwsrSIU",
        "outputId": "7a9f86b1-74ac-42b7-85c9-7cd5bb6a23aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4733, 0.3815],\n",
            "        [0.4754, 0.9401]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Find the maximum and minimum values of the output of 7."
      ],
      "metadata": {
        "id": "4iFNNCZFrh6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mx = torch.max(matrix_multiplication)\n",
        "mn = torch.min(matrix_multiplication)\n",
        "print(f\"maximum value in the tensor is {mx}\\n minimum value in the tensor is {mn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-DSM8cXrj41",
        "outputId": "df620d18-abb8-408e-edf8-965d6b4eda53"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maximum value in the tensor is 0.9400702714920044\n",
            " minimum value in the tensor is 0.3814699351787567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Find the maximum and minimum index values of the output of 7."
      ],
      "metadata": {
        "id": "CmU5dfTUtSGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mx_idx = torch.argmax(matrix_multiplication)\n",
        "mn_idx = matrix_multiplication.argmin()\n",
        "\n",
        "print(f\"maximum is at {mx_idx}\\n minimum is at {mn_idx}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07PkBtentV3Q",
        "outputId": "5c764adc-6256-4705-aa79-9b1e9ebfa555"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maximum is at 3\n",
            " minimum is at 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Make a random tensor with shape (1, 1, 1, 10) and then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). Set the seed to 7 when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape."
      ],
      "metadata": {
        "id": "omUxxwUPu6m7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(7)\n",
        "temp_tensor = torch.rand(1,1,1,10)\n",
        "ones_tensor = torch.ones_like(temp_tensor)\n",
        "print(f\"temp_tensor = {temp_tensor} with shape = {temp_tensor.shape}\")\n",
        "print(f\"ones-tensor = {ones_tensor} with shape = {ones_tensor.shape}\")\n",
        "\n",
        "squeezed_tensor = torch.squeeze(temp_tensor)\n",
        "print(f\"squeezed version of temp-tensor = {squeezed_tensor} with shape = {squeezed_tensor.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO8h6xVRu8rU",
        "outputId": "1eba9371-8230-495c-d852-8a162db367e5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "temp_tensor = tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
            "           0.3653, 0.8513]]]]) with shape = torch.Size([1, 1, 1, 10])\n",
            "ones-tensor = tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]]) with shape = torch.Size([1, 1, 1, 10])\n",
            "squeezed version of temp-tensor = tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
            "        0.8513]) with shape = torch.Size([10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matrix_multiplication)\n",
        "shp = matrix_multiplication.shape\n",
        "print(f\"shape of matrix_multiplication = {shp}\")\n",
        "print(f\"maximum value = {matrix_multiplication[mx_idx//shp[0],mx_idx%shp[1]]}\")\n",
        "print(f\"minimum value = {matrix_multiplication[mn_idx//shp[0],mn_idx%shp[1]]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKSes9DVcu0A",
        "outputId": "18513d5b-6dda-4314-e22b-defdd5b59dde"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4733, 0.3815],\n",
            "        [0.4754, 0.9401]], device='cuda:0')\n",
            "shape of matrix_multiplication = torch.Size([2, 2])\n",
            "maximum value = 0.9400702714920044\n",
            "minimum value = 0.3814699351787567\n"
          ]
        }
      ]
    }
  ]
}