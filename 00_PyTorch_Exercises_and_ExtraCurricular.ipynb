{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Documentation reading:\n",
        " A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness). See the documentation for `torch.Tensor` and `torch.cuda`"
      ],
      "metadata": {
        "id": "d0xUsiTZi9n5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Create a random tensor with shape (7, 7)."
      ],
      "metadata": {
        "id": "y_Kysws6lBN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "tensor = torch.rand(7,7)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cnXRvYrlKXu",
        "outputId": "77ef24bb-f24f-404c-ec50-ab2710bf5760"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7749, 0.8208, 0.2793, 0.6817, 0.2837, 0.6567, 0.2388],\n",
            "        [0.7313, 0.6012, 0.3043, 0.2548, 0.6294, 0.9665, 0.7399],\n",
            "        [0.4517, 0.4757, 0.7842, 0.1525, 0.6662, 0.3343, 0.7893],\n",
            "        [0.3216, 0.5247, 0.6688, 0.8436, 0.4265, 0.9561, 0.0770],\n",
            "        [0.4108, 0.0014, 0.5414, 0.6419, 0.2976, 0.7077, 0.4189],\n",
            "        [0.0655, 0.8839, 0.8083, 0.7528, 0.8988, 0.6839, 0.7658],\n",
            "        [0.9149, 0.3993, 0.1100, 0.2541, 0.4333, 0.4451, 0.4966]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape (1, 7)\n",
        "(hint: you may have to transpose the second tensor)."
      ],
      "metadata": {
        "id": "viBk2O50llkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor1 = torch.rand(1,7)\n",
        "tensor2 = torch.rand(1,7)\n",
        "\n",
        "print(tensor1.shape)\n",
        "print(tensor2.T.shape)\n",
        "print(torch.mm(tensor1, tensor2.T))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OGiO_s2lz-P",
        "outputId": "c8534c1d-615c-4160-eaf5-7a496382734c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 7])\n",
            "torch.Size([7, 1])\n",
            "tensor([[1.6949]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Set the random seed to 0 and do exercises 2 & 3 over again."
      ],
      "metadata": {
        "id": "Ief6ZURkmPpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_SEED = 0\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "# 2nd:\n",
        "tensor_seed = torch.rand(7,7)\n",
        "print(tensor_seed)\n",
        "\n",
        "# 3rd:\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "tensor_A = torch.rand(1,7)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "tensor_B = torch.rand(1,7)\n",
        "\n",
        "print(f\"tensor_A = {tensor_A}\\n tensor_B transpose = {tensor_B.T}\")\n",
        "print(torch.matmul(tensor_A, tensor_B.T))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA0iiu6LmUOG",
        "outputId": "4134df06-be4b-49a4-a503-70cd8b8c1ef2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901],\n",
            "        [0.8964, 0.4556, 0.6323, 0.3489, 0.4017, 0.0223, 0.1689],\n",
            "        [0.2939, 0.5185, 0.6977, 0.8000, 0.1610, 0.2823, 0.6816],\n",
            "        [0.9152, 0.3971, 0.8742, 0.4194, 0.5529, 0.9527, 0.0362],\n",
            "        [0.1852, 0.3734, 0.3051, 0.9320, 0.1759, 0.2698, 0.1507],\n",
            "        [0.0317, 0.2081, 0.9298, 0.7231, 0.7423, 0.5263, 0.2437],\n",
            "        [0.5846, 0.0332, 0.1387, 0.2422, 0.8155, 0.7932, 0.2783]])\n",
            "tensor_A = tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901]])\n",
            " tensor_B transpose = tensor([[0.4963],\n",
            "        [0.7682],\n",
            "        [0.0885],\n",
            "        [0.1320],\n",
            "        [0.3074],\n",
            "        [0.6341],\n",
            "        [0.4901]])\n",
            "tensor([[1.5985]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Speaking of random seeds, we saw how to set it with torch.manual_seed() but is there a GPU equivalent? (hint: you'll need to look into the documentation for torch.cuda for this one). If there is, set the GPU random seed to 1234."
      ],
      "metadata": {
        "id": "ZnYRGpkbmaAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "torch.cuda.manual_seed(1234)\n",
        "\n",
        "tensor_cuda_random = torch.rand(4,4)\n",
        "\n",
        "print(tensor_cuda_random)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u08uSgptnmqx",
        "outputId": "faeac9d0-8d18-4f0e-9d57-02833626618f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Apr 29 16:34:20 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0              29W /  70W |    151MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n",
            "True\n",
            "tensor([[0.8964, 0.4556, 0.6323, 0.3489],\n",
            "        [0.4017, 0.0223, 0.1689, 0.2939],\n",
            "        [0.5185, 0.6977, 0.8000, 0.1610],\n",
            "        [0.2823, 0.6816, 0.9152, 0.3971]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Create two random tensors of shape (2, 3) and send them both to the GPU (you'll need access to a GPU for this). Set torch.manual_seed(1234) when creating the tensors (this doesn't have to be the GPU random seed)."
      ],
      "metadata": {
        "id": "9m3gkBIxpZrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1234)\n",
        "cpu_tensor1 = torch.rand(2,3)\n",
        "cpu_tensor2 = torch.rand(2,3)\n",
        "\n",
        "print(f\"cpu_tensor1 device = {cpu_tensor1.device} \\t cpu_tensor2 device = {cpu_tensor2.device}\")\n",
        "\n",
        "device = \"cuda\" if(torch.cuda.is_available()) else \"cpu\"\n",
        "gpu_tensor1 = cpu_tensor1.to(device = device)\n",
        "# gpu_tensor2 = cpu_tensor2.cuda(device = device)\n",
        "gpu_tensor2 = torch.rand([2,3], device = device)\n",
        "\n",
        "print(f\"gpu_tensor1 device = {gpu_tensor1.device} \\t gpu_tensor2 device = {gpu_tensor2.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9Ubtu4Tpd-L",
        "outputId": "283573e6-7b25-416c-e261-6e926b5609cb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu_tensor1 device = cpu \t cpu_tensor2 device = cpu\n",
            "gpu_tensor1 device = cuda:0 \t gpu_tensor2 device = cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors)."
      ],
      "metadata": {
        "id": "Shf1OJzlrPb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix_multiplication = torch.mm(gpu_tensor1, gpu_tensor2.T)\n",
        "print(matrix_multiplication)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvwEBYwsrSIU",
        "outputId": "ab568864-6693-459b-ae2a-64648d7afd1a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4733, 0.3815],\n",
            "        [0.4754, 0.9401]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Find the maximum and minimum values of the output of 7."
      ],
      "metadata": {
        "id": "4iFNNCZFrh6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mx = torch.max(matrix_multiplication)\n",
        "mn = torch.min(matrix_multiplication)\n",
        "print(f\"maximum value in the tensor is {mx}\\n minimum value in the tensor is {mn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-DSM8cXrj41",
        "outputId": "e46a44bd-4200-432e-f098-e2b3eb0e5406"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maximum value in the tensor is 0.9400702714920044\n",
            " minimum value in the tensor is 0.3814699351787567\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Find the maximum and minimum index values of the output of 7."
      ],
      "metadata": {
        "id": "CmU5dfTUtSGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mx_idx = torch.argmax(matrix_multiplication)\n",
        "mn_idx = matrix_multiplication.argmin()\n",
        "\n",
        "print(f\"maximum is at {mx_idx}\\n minimum is at {mn_idx}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07PkBtentV3Q",
        "outputId": "508165ed-4a11-4a99-dc14-59cfa0c9b0b2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maximum is at 3\n",
            " minimum is at 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Make a random tensor with shape (1, 1, 1, 10) and then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). Set the seed to 7 when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape."
      ],
      "metadata": {
        "id": "omUxxwUPu6m7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(7)\n",
        "temp_tensor = torch.rand(1,1,1,10)\n",
        "ones_tensor = torch.ones_like(temp_tensor)\n",
        "print(f\"temp_tensor = {temp_tensor} with shape = {temp_tensor.shape}\")\n",
        "print(f\"ones-tensor = {ones_tensor} with shape = {ones_tensor.shape}\")\n",
        "\n",
        "squeezed_tensor = torch.squeeze(temp_tensor)\n",
        "print(f\"squeezed version of temp-tensor = {squeezed_tensor} with shape = {squeezed_tensor.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO8h6xVRu8rU",
        "outputId": "c74e9a0d-1317-469d-9e89-e2b9499a61db"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "temp_tensor = tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
            "           0.3653, 0.8513]]]]) with shape = torch.Size([1, 1, 1, 10])\n",
            "ones-tensor = tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]]) with shape = torch.Size([1, 1, 1, 10])\n",
            "squeezed version of temp-tensor = tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
            "        0.8513]) with shape = torch.Size([10])\n"
          ]
        }
      ]
    }
  ]
}